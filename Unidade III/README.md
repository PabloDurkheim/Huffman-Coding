# üöÄ Otimiza√ß√£o e An√°lise Comparativa de Escalabilidade

---

## üîß Paraleliza√ß√£o do Gargalo

A Figura 2 ilustra a solu√ß√£o adotada para paralelizar o gargalo do c√≥digo.

![Paraleliza√ß√£o do gargalo do Compressor](./Figura2.jpeg)

Cada √≠ndice do vetor representa uma thread, e cada caractere possui um √≠ndice.  

Para que uma thread possa buscar bits restantes corretamente, s√£o necess√°rias tr√™s informa√ß√µes:  
- Se a thread anterior deixou bits restantes.  
- Onde ocorreu a √∫ltima escrita (caractere).  
- Quantos bits sobraram do √∫ltimo caractere escrito.  

Para armazenar essas informa√ß√µes, foram criados os vetores:  
- `bits_restantes_total_`  
- `fim_de_cada_thread`  
- `bits_restante_atual`  

Al√©m disso, para que a thread escreva corretamente no arquivo comprimido, √© preciso posicionar o ponteiro de escrita com base em:  
- Quantidade de vezes que a thread anterior escreveu (`qtd_de_escrita`)  
- Posi√ß√£o final da escrita da thread anterior (`posicao_final_de_escrita`)  

Todo esse c√°lculo foi realizado previamente para viabilizar a paraleliza√ß√£o com sucesso.

---

## ‚öñÔ∏è Paraleliza√ß√µes Testadas

Ap√≥s a paraleliza√ß√£o do gargalo, foi identificado que as fun√ß√µes `fread` e `fwrite` **n√£o s√£o thread-safe**.  
Para proteger essas opera√ß√µes, foram testadas vers√µes usando:  
- `critical`  
- `ordered`  
- `omp_set_lock` / `omp_unset_lock`  

Por√©m, essas prote√ß√µes causaram **travamentos** frequentes entre as threads durante as chamadas ao sistema operacional, fazendo com que as opera√ß√µes de leitura e escrita ocorressem de forma sequencial, mesmo com o c√≥digo paralelizado.  
Devido a esse impacto negativo, todas as vers√µes paralelizadas foram descartadas.

---

## üì¶ Buffer

Foi testada a implementa√ß√£o de um **buffer com tamanho fixo** em partes espec√≠ficas do c√≥digo do Compressor.  
Esse buffer permite a leitura de blocos maiores de dados de uma s√≥ vez, reduzindo chamadas ao sistema operacional e aberturas de arquivo, melhorando a efici√™ncia em compara√ß√£o com a vers√£o original, no entanto, n√£o conseguimos chegar em uma vers√£o final com o buffer.

De modo geral, o desempenho melhora conforme o tamanho do buffer aumenta, principalmente para arquivos maiores, devido √† redu√ß√£o do overhead.

### Resultados dos testes de tempo de execu√ß√£o (em segundos):

| Tamanho do buffer (caracteres) | Tempo de execu√ß√£o (s) |
|-------------------------------|----------------------|
| 1                             | 22,780238            |
| 100                           | 2,334518             |
| 1.000                         | 2,113496             |
| 10.000                        | 2,082477             |
| 1.000.000                     | 1,896297             |

Esses n√∫meros mostram que buffers pequenos geram muitas chamadas ao sistema, aumentando o tempo, enquanto buffers maiores reduzem esse overhead e aceleram o processamento.

---

## üéØ Projeto Final

Dado que as paraleliza√ß√µes testadas deterioraram o desempenho e a implementa√ß√£o do buffer n√£o foi conclu√≠da, decidiu-se manter a **vers√£o do projeto 2**, com o gargalo serializado e a paraleliza√ß√£o para m√∫ltiplos arquivos.  

Essa foi a melhor vers√£o testada e foi submetida a testes no NPAD com m√∫ltiplos arquivos, visando avaliar a escalabilidade mantendo as paraleliza√ß√µes j√° implementadas.

---

## üìö Refer√™ncias

- GeeksforGeeks. *Huffman Coding | Greedy Algo-3*. Dispon√≠vel em:  
  [https://www.geeksforgeeks.org/huffman-coding-greedy-algo-3/](https://www.geeksforgeeks.org/huffman-coding-greedy-algo-3/). Acesso em: 08 nov. 2024.

- HENGIRMEN, E. *Huffman Coding*. Dispon√≠vel em:  
  [https://github.com/e-hengirmen/Huffman-Coding/tree/master](https://github.com/e-hengirmen/Huffman-Coding/tree/master). Acesso em: 29 out. 2024.

- PACHECO, Peter S. *An Introduction to Parallel Programming*. Burlington: Morgan Kaufmann, 2011.
